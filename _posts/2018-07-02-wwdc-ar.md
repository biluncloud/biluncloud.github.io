---
layout: post
title: WWDC之AR
description: 首次参加2018年苹果的WWDC，感受颇深。AR在这次大会中占了非常大的比重，苹果的AR生态已经接近布局完成，期待后续产品
tags: WWDC, AR, ARKit, Metal, OpenGL ES, AR Quick Look, USDZ, glTF
image:  wwdc.png
---

进入iOS开发这些年，今年终于有机会去参加一次WWDC，朋友们笑称，这是趟朝圣之旅，我想也并不为过。

{{ more }}

### 目录
{:.no_toc}

* Table of Contents Placeholder
{:toc}

-----

## 背景

与往年的抢票不同，今年的门票采用随机抽取的方式，早在三月份就开始了WWDC08的门票登记，而我有幸抽中门票，随后开始了漫长的签证。运气很不好，不知是否是由于中美关系紧张的缘故，IT相关的从业者很容易被行政审查。我在广州大使馆也不幸被抽中，当时准备了WWDC的邀请函，丝毫没有用处。面试官问有没有准备个人简历与旅行计划，这些在网上看攻略时都说不用准备，没想到却刚好被问到，行政审查，让回去准备这些材料并发到大使馆的邮箱。于是开始了漫长的等待期，平均时间是25天左右就能够issue签证，我的却一直等了42天，中间写了几次邮件去催促，无果。准备放弃之际，却在5月底拿到签证，接着匆忙的准备酒店、机票等事宜，赶上了这次WWDC。

## AR@WWDC

这次参会主要关注AR方面，AR在今年的大会上占尽了风头。Keynote主题演讲时，iOS 12的性能数据介绍之后，立刻开始了AR相关的介绍，作为iOS最重要的特性登场。下面带着大家一起看看这次的AR都包含了哪些内容。

### USDZ格式

第一个主题，苹果发布了新的格式`USDZ`，它是基于Pixar开源的`USD`格式，不同的是前者把所有文件都打包成了一个文件，为分享做了一些优化，并且在Xcode 10中集成了打包转码工具。这个发布很有意思，苹果似乎总是与业界对着来，关于3D文件格式，`Khronos`组织已经与2015年就发布了`glTF`格式，并且已经在各大厂商、游戏引擎中得到了推广，`Khronos`声称，`glTF`就是3D格式中的`jpeg`，俨然一副建立业界新标准的姿态。即使在`glTF`已经占有如此大优势的情况下，苹果仍然执意发布自己的3D格式，就好像`Metal`与`Vulkan`，苹果自己构建一道与业界的屏障，也许是因为它可以完全控制自己的硬件与软件，不需要因为兼容性去妥协设计吧。至于最终`USDZ`能否像`glTF`一样成功，看后面苹果的推广了。

这里对`glTF`与`USD/USDZ`作了一个简单的对比：

|          | glTF                                           | USD/USDZ            |
| -------  | ---------------------------------------------- | ------------------- |
| 用途     | 兼容GPU的数据格式，快速加载                    | 用于分享，扩展      |
| 支持     | Khronos, Facebook, Google, Microsoft, Adobe    | Apple, Pixar        |
| 引擎     | UE4, Unity 3D, godot, three.js, Blender, Adobe | Apple               |
| 工具     | 集成的转换器，优化，校验，编辑工具等等         | Xcode命令行         |
| 版本     | 2.0                                            | 1.0                 |
| 发布时间 | 2015.10.19 1.0/2017.6.5 2.0                    | 2012 USD/2018 USDZ  |
| 开源     | 开源                                           | 2016年开源          |

目前看来，`USD/USDZ`全方位的落后，不过因为它是刚刚发布，相信凭着苹果的运营，会得到越来越多的支持与推广。

苹果推出这个格式，有一个非常重要的原因，为了`AR Quick Look`。

### AR Quick Look

本次大会一个非常重要的发布，`AR Quick Look`，这是一个什么东西？可以理解为默认的图片浏览器之于图片，这个就是3D文件的浏览器，它将在下一个版本的iOS、macOS中原生支持，已经支持了众多的原生应用，如下图所列：

![arquicklook-support](/img/posts/wwdc-arquicklook-support.png)

另外苹果做了件事让这个更加容易推广，可以像开发者直接使用`MPMoviePlayerController`来播放视频一样，它将`AR Quick Look`也开放给开发者，使开发者可以通过简单的代码就集成这个工具，让应用支持AR能力。

既然叫**AR** Quick Look，自然不仅仅能展示3D模型，还可以与实景结合起来，直接使用`ARKit`的跟踪功能，体验非常好。看下面的两个例子：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIzNDQ1Mg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

看到这里，似乎明白苹果为何要发布新的3D格式了，这两者的结合不仅让3D模型可以更方便的在iOS与macOS里面原生支持，并且开发者可以通过两种方式简单的使用强大的能力：在app中集成`AR Quick Look`或者在H5的网页中使用新提供的`<ar>`标签。尤其是后者，此处可以展望一下，继`video`标签之后，`ar`很可能会被纳入到H5的标准之中，只不过可能格式不是使用`USDZ`，而是支持更加广泛的`glTF`吧，我们拭目以待。

接入`AR Quick Look`之后，会随着它本身的升级而自动升级，极大的降低了3D模型与AR场景的门槛，苹果下得一手好棋。

### 与Adobe合作

一个巴掌拍不响，3D格式的支持离不开其它大厂商的支持，苹果已经与Autodesk、Adobe等厂商合作，尤其是Adobe，他们的CTO被请来大会现场，专门展示了为苹果新的`USDZ`与`AR Quick Look`开发的工具链，可以在Adobe强大的工具链中完成从设计到绘图，到3D制作，到生成3D模型，最终发布在苹果的生态系统中，十分强大，一起来感受一下。

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIzMTIyOA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

### 尺子app

苹果将一个尺子app列入iOS 12系统的默认软件中，它可以利用`ARKit`的能力来测量真实世界中的物体长度。由于在iOS 11 beta版本发布时，就已经看到过了类似的应用，所以再次看到时并没有很激动。只是在体验上苹果做得更好，像计算器一样集成在手机中，为生活提供了极大的便利。

从与苹果工程师的沟通中了解到，这个精度比较高，只有5%以内的误差，1m只是不到5cm的误差，基本可以满足生活中的一般测量需要了。

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIxNjQ0OA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

### 共享地图

终于，苹果将这个功能开放了出来，3D的虚拟地图可以共享，如此一来，多个用户看到的可以是同一个虚拟世界，多人互动的AR游戏便成了可能。相信这个发布之后，AR游戏将会迎来一个大暴发。

大会展示了一个双人AR游戏，还有一个观看者，三者同时处于一个虚拟现实结合的世界中，好像将游戏中的功能搬了出来，直接由AR单机游戏变成了AR联机游戏，游戏性将极大丰富。

这个AR游戏也成为了一个开源的sample可以下载，并且还有其开发者手把手解析这个游戏的代码，感兴趣的同学可以去观摩下这个视频: [Inside SwiftShot: Creating an AR Game](https://developer.apple.com/videos/play/wwdc2018/605/)。

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIzMzc3Mg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

### 乐高世界

上面的游戏还不过瘾，苹果又邀请了一家大公司来撑场面：乐高。他们基于前面提到的共享地图与后面将要介绍的模型识别，将乐高玩具极其真实的还原到一个AR游戏中，趣味性十足。想想这种场景，孩子拉着父母来到乐高店中，店里摆放了众多的乐高模型，拿起手机一扫，AR便将这些模型直接搬到游戏之中，孩子可以在AR游戏中体验各种乐高模型，在极大的满足之后，离开店里是不是就到了父母们掏腰包的时间:-P。

因为还提供了保存的功能，孩子们还可以将游戏进度保存下来，下次进店接着上次结束的地方继续游戏，孩子们一定会爱死这个功能。

一起来感受下乐高的世界：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIzMjE3Ng==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>
    
## ARKit 2.0新特性

介绍完前面提到的AR能力之后，再来从开发者角度看看iOS 12为开发者带来了哪些新特性。ARKit 2.0将在这个版本发布，经历了开创性的ARKit 1.0与持续增强的ARKit 1.5版本之后，新版本ARKit又迎来了较大的更新，AR体验将进一步得到提升。

### 地图持久化

这是2.0版本提供的最重要的功能，前面已经分析过，有了它之后，多人互动成为了可能。同苹果的工程师了解了下，这与重定位的原理类似，在1.5版本中，ARKit提供了压后台再回前台之后的恢复功能，两者的原理一样。这个所谓的地图中存储了哪些信息呢？如下图：

![wwdc-arworldmap](/img/posts/wwdc-arworldmap.png)

主要包含：

- 特征点及其描述子。
- 已经放置的锚点信息，如此一来，之前在检测到平面，以及其它用户放置的模型都可以保存。
- 还有原始的特征点，即接口中提供的raw data。

下面是一个直观的地图建立的过程：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIzMDM4OA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

正是因为提供了地图持久化的功能，用户之间可以分享地图，也可以保存再加载地图，类似于游戏中保存进度一样，游戏性大大提升。

本以为这个功能可以用在室内导航中，但是咨询苹果工程师之后，由于数据量的原因，这只能够支持普通房间大小，所以不能够直接用于室内导航，可能需要多个地图拼接在一起才行。

### World Tracking增强

ARKit 2.0对于world tracking做了大量的增强，主要包含以下方面：

- 更快的初始化速度与平面检测更快。如果熟悉ARKit版本的同学，可能会知道，在ARKit 1.0版本时，初始化的速度非常慢，一般需要5s左右的时间才能够结束，在这5s的时间内，相机只能够传递传感器的方向信息，并没有深度的变化。所以在app的设计上都存在一个引导的过程。为此我们在支付宝中基于slam算法对其专门做了一个优化，一帧就可以初始化完成，解决了初始化引导的问题。到了ARKit 1.5，初始化速度有了提升，只需要3s左右；而到了最新的版本，据说只需要1s左右就能够完成，这样体验会大大提升，可以抛弃长时间的引导动画了。
- 跟踪与平面检测更加稳定。
- 更加精确的平面检测。这与前面提到过的误差范围只有5%有关系，在之前的使用过程中，经常会出现检测到的平面边界无法与真实平面吻合的情况，对真实性的还原有一定的影响。优化之后，这类情形会得到改善。
- 持续对焦。这个功能其实在ARKit 1.5版本就已经支持，预览画面会好很多，否则会出现画面一直模糊的情况。同时跟踪的稳定性并没有受到影响。后面将要提到的图像跟踪与物体跟踪也同样支持。
- 增加了4:3的视频帧采集。第一个版本时，只能够使用1280P的视频帧，现在更加灵活。可能后续会开放更多的AVCaptureSession的参数。

### 环境纹理

在ARKit 2.0中，苹果引入了一个除地图保存以外最令人激动的功能——环境纹理，它可以大大提高渲染真实性。环境纹理能让模型反射其它物体，反射的可以是虚拟物体，也可以是由真实环境建立的真实物体。它是利用天空盒子提供的纹理信息，当成光照来达到反射的目的，这一过程也叫做`Image Based Lighting`，这一关键点在于提供天空盒子。ARKit 2.0支持直接从摄像头拍摄的真实场景中获取这个天空盒子，它是自动构建的，不需要360度扫描。并且这个天空盒子还可以自动更新，至于更新的时机完全由内部机制决定。下面这个视频展示了天空盒子的构建过程：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyOTEzMg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

从过程来看，其实是运用了ARKit的平面检测功能，它将平面上的纹理大致的贴到了天空盒子对应的平面中，随着平面信息不断的更新，天空盒子中的纹理也逐步完整。

对比下使用环境纹理之后的效果：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyNzg3Mg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

可以看出，环境纹理功能打开之后，虚拟的金属碗逐渐反射出来真实世界的香蕉和桌面，真实性得到极大的提升，可以说，它是虚拟与现实融合的纽带。

### 图像跟踪

自从ARKit 1.5版本提供了图像识别之后，图像跟踪也在这个版本得到了支持。做得非常好的一点在于，帧率高达60fps，跟踪效果极其稳定，同时可以多个跟踪目标。可以看下面的视频，红绿蓝的坐标轴是虚拟的模型：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyNjc4NA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

模型与图片帖合的非常好，并且跟踪过程稳定。支付宝在第一个AR就已经支持了图像跟踪，处理时间只需要3ms左右，可以达到60fps，但目前只能够跟踪一个目标。

因为图像跟踪对图片的质量有比较高的要求，图像内容越丰富，跟踪的效果越好，所以Xcode还提供了图像质量检测功能，如下面的两个识别图：

![wwdc-image-quality](/img/posts/wwdc-image-quality.png)
![wwdc-image-quality-xcode](/img/posts/wwdc-image-quality-xcode.png)

Xcode结出了非常详细的警告信息，如直方图的分布过窄、重复性结构过多、纯色区域过多等，同时给出了优化的建议，这个功能非常赞。在这一点上，支付宝的AR平台是在上传跟踪图像时，在服务端对图像进行打分判定是否能够跟踪，只有过了分数线才支持跟踪。但并没太多的提示信息，对于经验丰富的开发者，这点不是问题，但如果是新手，可能不太友好。

苹果给出了一个效果更酷的例子，直接可以在图像跟踪的位置播放视频：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyNTUzMg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

这个功能支付宝也早在一年前已经支持，并且更进一步，我们还支持透明视频：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5OTY4NzA0MA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

### 物体识别

图像识别可以适用于很多场景，但对于某些场合，仅用一张图像不够的，比如博物馆的展品。用户可能从任意角度去扫描这些展品，如果使用图像识别的话，需要不同角度非常多的识别图像。有没有更好的方案？苹果给出了物体识别，不同于图像识别，物体识别可以从各个角度识别物体，完美的适用于前面提到的博物馆场景。识别物不再是多张图像，而直接是一个3D的物体。如下视频所示，从任意角度识别到一个展品之后，在对应的位置放置一个展品信息的模型，后续的跟踪还是world tracking。

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyNDYxMg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

图像识别是提供图像，而物体识别则是提供一个预先扫描好的模型，所以它的制作成本稍高。这个模型有点类似于前面提到的地图，它也是一些特征点等信息的集合，原理上应该与可共享的地图一致。苹果还提供了一个专门的工具来对物体进行扫描，降低了识别模型的制作成本。

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyMjg1Mg==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

### 人脸跟踪

从iPhone X开始，苹果引入了前置深度相机，这次也有一些新功能的发布，如支持眼球跟踪：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyMjE0NA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

以及支持舌头跟踪：

<div style="position:relative;padding-top:56.25%;">
    <iframe src="http://player.youku.com/embed/XMzY5NDIyMDIyNA==" allowtransparency="true" allowfullscreen="true" scrolling="no" border="0" frameborder="0" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
</div>

这让各种表情变得更加有趣了。但由于这些是基于深度相机，所以只能在iPhone X这款支持前置深度相机的机型才支持。

## 其它

除了AR相关的新特性以外，这次大会还有些其它有意思的内容，不妨也在这里和大家分享一下。

### Siri Shortcuts

这是一个能够将手机上的应用都连接起来的功能，类似功能可以怎么玩，网上有个段子脑洞很大：
> 一旦老婆的Twitter上出现“加班”字样，立即激活一条手机短信通知。同时，自动检测谷歌日历，找出几个今晚没有事情的老友。随后，在Facebook上新建一个活动“今晚喝大酒”，一旦超过3人同意，触发一条订餐消息给餐厅。餐厅查询Evernote，找到这群人最喜欢的菜和酒。

也类似于现在的智能家居，比如地图上检测到我即将到家时，打开客厅的灯，空调根据当前季节调到合适的温度，放首我最喜欢的音乐。这不算什么新东西，类似的服务workflow、ifttt已经存在多年，可以连接应用，只是国内支持的服务很少，国外也感觉只在开发者中间流行。

苹果是在2017年收购了workflow，现在将Siri与其结合，推出新的shortcuts，由于与Siri可以很好的整合在一起，一方面，Siri的能力更强，正在努力摆脱玩物的尴尬场面。另一方面，有了Siri之后操作shortcuts更加方便，也更加智能。第三方应用也可以提供接入shortcuts的功能，这将赋于shortcuts更加强大的能力。同时Siri可以根据用户不同的习惯提供不同的建议。将来会不会有类似于app store一样的小平台，提供shortcuts的分享，这个功能将来变成什么样，非常值得期待。

### Metal

苹果已经坚定了要大力发展它的API: Metal，从下个版本开始OpenGL/ES将会废除，不再提供更多的支持。我在Labs中提了一个OpenGL ES不能在iOS 11的机器上Capture GPU Frame的问题，本来与苹果工程师聊的时候，他说是应该支持的，让我提了bug，结果没多久便收到bug被closed的消息，理由是没有修复的计划。OpenGL/ES的玩家将要无情的被抛弃了。

虽然说要被废除，但是就像其它的废弃API一样，还有一段时间的生存期，苹果一样会留给开发者很长的缓冲时间。现在依然有很多iOS 2.0版本的废弃API还能够运行。

不过苹果在Metal上的优化，非常让人动心，并且专门有Session来讲述如何从OpenGL/ES迁移到Metal来，还请了一个游戏公司的开发者来讲述他们迁移的经验，游戏性能获取了巨大的提升，也并没有太大的工作量，这样结果似乎更加令人信服。

前面提到Xcode可以Capture GPU Frame，现在在Metal更进一步，可以调试shader，这一点真的是太赞，将极大的提升shader的编程，但是很可惜，仍然只能够用在Metal中，OpenGL/ES是无法享受此待遇的。

### ML

AR与ML是这次大会上非常重要的两个主题，ML也迎了较多的更新。首先它提供了一个新的CreateML的框架，可以直接用MBP通过playground来训练模型，10行以内的代码就搞定，并且模型压缩比高的夸张。由于是直接在Metal基础上开发，所以可以利用GPU的高性能来对模型进行训练，宣称MBP可以用48分钟训练完其它机器上需要24小时才能训练完成的模型。

最后一个有趣的是，ML直接支持语义分析，并且支持多国语言，包含中文。

### Xcode 10

Xcode 10有几个比较有趣的更新，支持多光标、列选择，这两个功能早在很多现代的编辑，VIM，Emacs中就已经支持，不算惊喜。

另外一个功能是可以并行运行UT，这个功能很好，现在我们的UT在simulator上面运行一次需要半个小时左右，支持并行UT之后，可以极大的减少UT的时间。它的原理是通过clone出来多个simulator来执行，每个simulator分配了不同的测试用例，执行完成之后，再将结果汇总起来。之前在西门子时，我们也尝试过使用Hadoop来并行跑测试用例的方案，与这个原理一样。

### macOS

macOS也将迎来新版本macOS Mojave，不过没想到的是在主题演讲时第一点竟然介绍的是dark mode，顿时倍感失望，仅仅是一个主题，竟然作为一个新系统版本的主要卖点着重介绍。

有一个比较激动的点，后面版本会让iOS上的应用非常方便的移植在Mac上，大大的降低两个版本之间的开发成本，iOS上这么多年积累的优秀应用也许也可以在Mac上大放异彩。

这个版本持续的在与手机端无缝合作上下功夫，苹果在体验上的不懈追求宠坏了用户，让用户不知不觉间就习惯了这种特性，觉得这似乎是理所当然的，没有这个功能反而觉得奇怪，比如之前的Mac与iPhone剪贴板打通，非常体贴。

### FaceTime

facetime下个版本将支持最多同时32人通话，查了下微信、QQ，都是最多添加9人，但由于受限于平台，在国内还是无法流行起来，微信与QQ是更好的方案。但从技术层面来说，32人同时通话需要大量的带宽与渲染性能，看起来非常了不起。

### 非技术

其它还有一些非技术方面的体验也让我留了下很深的印象。大会包容万象，下至10岁，上至82岁，有身体健全人士，也有听力障碍人士，大会上不止一次的看到听力障碍人士对面坐着一个手语翻译工作人员给他们翻译演讲的内容。头发花白、胡子大把的开发者随处可见，大家来自不同国家，说着不同的语言，都聚集于此。

大会的形式也颇有新意，采用Session与Labs结合，Session类似学校时的课堂，不仅讲述新的特性，很多开发者可能会遇到的问题也会独自成章。开发者们可以参加自己感兴趣的主题，四天时间总共有一百多个Session。

![wwdc-session](/img/posts/wwdc-session.jpg)

除了Session以外，专门还有一对一的答疑时间，叫做Labs，这可能是WWDC门票里面最值回票价的环节，开发者可以就几乎任何相关的问题与苹果工程师一对一的对话。当然，不限于新特性，也可以咨询在使用这些framework中遇到的问题。除了这些技术性的Labs，还有UI Design Labs，可以就自己正在开发的app向苹果工程师咨询建议，但这种Labs需要提前预约，预约成功之后将得到半个小时的建议时间，非常宝贵。

![wwdc-labs](/img/posts/wwdc-labs.jpg)

在午餐时间，苹果还邀请了一些高校和企业来做分享，我去听了一个大学教授关于科技运用到考古学上的实践，还有一个Pixar的光照部门主管关于Pixar一些经典影片开发过程的分享。国外的企业与高校还有其它行业的结合非常紧密，比如很多软件对学生免费，这算是一个双赢的局面，企业既可以提升企业的公众形象，获取更好的政府及学校生源支持，还能够将科研领域的最新研究成果落地商业化。同样高校也可以通过企业的宣传机会，将自己的科研领域分享给大众，吸引更多的人来参与。这点国内的企业似乎做的不足，有种高校与企业各自发展，脱节的感觉。

最后一点，虽然乔布斯已经不在，但主题演讲仍然极受欢迎，大家热情不减，9点开始大会，凌晨3点就很多人去排队，为了可以离演讲台更近一些，似乎我们只有买火车票与孩子幼儿园报名才这样:-P。

### 视频地址

这里附上AR相关的session视频地址:

 - keynote: [https://developer.apple.com/videos/play/wwdc2018/101/](https://developer.apple.com/videos/play/wwdc2018/101/)
 - ARKit 2.0: [https://developer.apple.com/videos/play/wwdc2018/602/](https://developer.apple.com/videos/play/wwdc2018/602/)
 - AR Quick Look: [https://developer.apple.com/videos/play/wwdc2018/603/](https://developer.apple.com/videos/play/wwdc2018/603/)
 - 多人游戏: [https://developer.apple.com/videos/play/wwdc2018/605/](https://developer.apple.com/videos/play/wwdc2018/605/)
 - 理解跟踪: [https://developer.apple.com/videos/play/wwdc2018/610/](https://developer.apple.com/videos/play/wwdc2018/610/)
 - AR体验设计: [https://developer.apple.com/videos/play/wwdc2018/805](https://developer.apple.com/videos/play/wwdc2018/805)

## 写在最后

这是一个Geekers们的聚会，大家调侃这是朝圣，这是xie教聚会，大家狂热又专注，不分国度、肤色、语言，不远万里聚集于此。即使所有的Session内容都有视频，但就像你最爱的演唱会即使有DVD，也一定要去现场感受一次一样。对了，这里还是为数不多的男厕排长队，而女厕空荡荡的奇妙地方。这里是WWDC。

(全文完)

feihu

2018.07.02 于 Shenzhen
